{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:28<00:00, 5885766.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n",
      "训练数据集的长度为:50000\n",
      "训练数据集的长度为:10000\n"
     ]
    }
   ],
   "source": [
    "# trainCIFAR.py\n",
    "from asyncore import write\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "curPath = os.path.abspath(os.path.dirname(\"modelCIFAR.py\"))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)\n",
    "from modelCIFAR import Net\n",
    "from torch.utils.tensorboard import SummaryWriter  # 关于tensorboard的使用\n",
    "\n",
    "# 训练数据集合测试数据集的准备\n",
    "train_data = torchvision.datasets.CIFAR10(root = \"../data\", train=True, \n",
    "transform=torchvision.transforms.ToTensor(), download=True) # 注意要将PIL图像转换成向量\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"../data\", train = False, \n",
    "transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# 查看训练数据集合测试数据集的长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size = len(test_data)\n",
    "\n",
    "# format字符串格式化，format中的变量替换{}\n",
    "print(\"训练数据集的长度为:{}\".format(train_data_size))\n",
    "print(\"训练数据集的长度为:{}\".format(test_data_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用Dataloader来加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建神经网络(10分类)\n",
    "net = Net()\n",
    "\n",
    "# 创建交叉熵损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器 设置优化的参数和学习速率\n",
    "learning_rate = 1e-2   # 0.01\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# 设置训练网络的参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----第1轮训练开始-----\n",
      "训练次数:100, loss: 2.2908287048339844\n",
      "训练次数:200, loss: 2.283921003341675\n",
      "训练次数:300, loss: 2.274627685546875\n",
      "训练次数:400, loss: 2.231511116027832\n",
      "训练次数:500, loss: 2.0906808376312256\n",
      "训练次数:600, loss: 2.0477702617645264\n",
      "训练次数:700, loss: 2.013421058654785\n",
      "整体测试集上的loss: 316.7603305578232\n",
      "整体测试集上的正确率: 0.2694999873638153\n",
      "模型已保存\n",
      "-----第2轮训练开始-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vitamink/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数:800, loss: 1.910315990447998\n",
      "训练次数:900, loss: 1.8641213178634644\n",
      "训练次数:1000, loss: 1.9227256774902344\n",
      "训练次数:1100, loss: 1.9627751111984253\n",
      "训练次数:1200, loss: 1.7137823104858398\n",
      "训练次数:1300, loss: 1.6793209314346313\n",
      "训练次数:1400, loss: 1.7559492588043213\n",
      "训练次数:1500, loss: 1.8092200756072998\n",
      "整体测试集上的loss: 303.2302030324936\n",
      "整体测试集上的正确率: 0.31189998984336853\n",
      "模型已保存\n",
      "-----第3轮训练开始-----\n",
      "训练次数:1600, loss: 1.74198317527771\n",
      "训练次数:1700, loss: 1.6731727123260498\n",
      "训练次数:1800, loss: 1.9179251194000244\n",
      "训练次数:1900, loss: 1.7241748571395874\n",
      "训练次数:2000, loss: 1.894544005393982\n",
      "训练次数:2100, loss: 1.525009274482727\n",
      "训练次数:2200, loss: 1.4688990116119385\n",
      "训练次数:2300, loss: 1.7759449481964111\n",
      "整体测试集上的loss: 272.5285631418228\n",
      "整体测试集上的正确率: 0.3725999891757965\n",
      "模型已保存\n",
      "-----第4轮训练开始-----\n",
      "训练次数:2400, loss: 1.7314164638519287\n",
      "训练次数:2500, loss: 1.3273792266845703\n",
      "训练次数:2600, loss: 1.59180748462677\n",
      "训练次数:2700, loss: 1.6896920204162598\n",
      "训练次数:2800, loss: 1.4609264135360718\n",
      "训练次数:2900, loss: 1.5987234115600586\n",
      "训练次数:3000, loss: 1.323833703994751\n",
      "训练次数:3100, loss: 1.4931076765060425\n",
      "整体测试集上的loss: 260.1261135339737\n",
      "整体测试集上的正确率: 0.4000999927520752\n",
      "模型已保存\n",
      "-----第5轮训练开始-----\n",
      "训练次数:3200, loss: 1.364493489265442\n",
      "训练次数:3300, loss: 1.4590144157409668\n",
      "训练次数:3400, loss: 1.4338171482086182\n",
      "训练次数:3500, loss: 1.5578128099441528\n",
      "训练次数:3600, loss: 1.5394495725631714\n",
      "训练次数:3700, loss: 1.376853346824646\n",
      "训练次数:3800, loss: 1.2928491830825806\n",
      "训练次数:3900, loss: 1.4459260702133179\n",
      "整体测试集上的loss: 248.8345229625702\n",
      "整体测试集上的正确率: 0.4284000098705292\n",
      "模型已保存\n",
      "-----第6轮训练开始-----\n",
      "训练次数:4000, loss: 1.365891933441162\n",
      "训练次数:4100, loss: 1.4128447771072388\n",
      "训练次数:4200, loss: 1.5285435914993286\n",
      "训练次数:4300, loss: 1.2329845428466797\n",
      "训练次数:4400, loss: 1.1536327600479126\n",
      "训练次数:4500, loss: 1.376292109489441\n",
      "训练次数:4600, loss: 1.3904715776443481\n",
      "整体测试集上的loss: 237.30630159378052\n",
      "整体测试集上的正确率: 0.45100000500679016\n",
      "模型已保存\n",
      "-----第7轮训练开始-----\n",
      "训练次数:4700, loss: 1.3138185739517212\n",
      "训练次数:4800, loss: 1.4933351278305054\n",
      "训练次数:4900, loss: 1.3731197118759155\n",
      "训练次数:5000, loss: 1.3550680875778198\n",
      "训练次数:5100, loss: 0.9726154208183289\n",
      "训练次数:5200, loss: 1.3114067316055298\n",
      "训练次数:5300, loss: 1.1724952459335327\n",
      "训练次数:5400, loss: 1.3479481935501099\n",
      "整体测试集上的loss: 226.17395675182343\n",
      "整体测试集上的正确率: 0.47920000553131104\n",
      "模型已保存\n",
      "-----第8轮训练开始-----\n",
      "训练次数:5500, loss: 1.2332056760787964\n",
      "训练次数:5600, loss: 1.1828924417495728\n",
      "训练次数:5700, loss: 1.18773353099823\n",
      "训练次数:5800, loss: 1.218432903289795\n",
      "训练次数:5900, loss: 1.3660932779312134\n",
      "训练次数:6000, loss: 1.5179166793823242\n",
      "训练次数:6100, loss: 1.0701758861541748\n",
      "训练次数:6200, loss: 1.0636451244354248\n",
      "整体测试集上的loss: 213.48145389556885\n",
      "整体测试集上的正确率: 0.5101000070571899\n",
      "模型已保存\n",
      "-----第9轮训练开始-----\n",
      "训练次数:6300, loss: 1.4240968227386475\n",
      "训练次数:6400, loss: 1.1030285358428955\n",
      "训练次数:6500, loss: 1.5303791761398315\n",
      "训练次数:6600, loss: 1.1012239456176758\n",
      "训练次数:6700, loss: 1.057978868484497\n",
      "训练次数:6800, loss: 1.1537387371063232\n",
      "训练次数:6900, loss: 1.086216926574707\n",
      "训练次数:7000, loss: 0.8517616391181946\n",
      "整体测试集上的loss: 203.09968823194504\n",
      "整体测试集上的正确率: 0.536899983882904\n",
      "模型已保存\n",
      "-----第10轮训练开始-----\n",
      "训练次数:7100, loss: 1.1889835596084595\n",
      "训练次数:7200, loss: 0.9704439640045166\n",
      "训练次数:7300, loss: 1.1239871978759766\n",
      "训练次数:7400, loss: 0.8198509812355042\n",
      "训练次数:7500, loss: 1.265690803527832\n",
      "训练次数:7600, loss: 1.228305459022522\n",
      "训练次数:7700, loss: 0.850619375705719\n",
      "训练次数:7800, loss: 1.290245532989502\n",
      "整体测试集上的loss: 194.9754102230072\n",
      "整体测试集上的正确率: 0.5598999857902527\n",
      "模型已保存\n"
     ]
    }
   ],
   "source": [
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"../logs_train\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----第{}轮训练开始-----\".format(i+1)) # i从0 - 9 \n",
    "\n",
    "    # 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = net(imgs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad() # 用优化器清零梯度\n",
    "        loss.backward()  # 得到每个参数节点的梯度\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step = total_train_step+1  # 训练完一次\n",
    "\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数:{}, loss: {}\".format(total_train_step, loss.item())) # item将tensor数据类型转换成数字\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 每次训练完一轮以后，在测试数据集上跑一遍，用测试数据集上的损失或者叫正确率来评估有没有训练好\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad(): #没有梯度。不会调优 \n",
    "        for data in test_dataloader:  # data的一部分数据在网络模型上的损失\n",
    "            imgs, targets = data\n",
    "            outputs = net(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_test_loss += loss.item()  # loss是一个张量转换成item标量\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "    print(\"整体测试集上的loss: {}\".format(total_test_loss))  \n",
    "    print(\"整体测试集上的正确率: {}\".format(total_accuracy / test_data_size))\n",
    "\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy/test_data_size, total_test_step)\n",
    "    total_test_step += 1  # 测试完一次\n",
    "\n",
    "    # torch.save(net, \"Net_{}.pth\".format(i))\n",
    "    # 官方推荐的保存模型\n",
    "    torch.save(net.state_dict(), \"Net_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "假设是一个二分类问题\n",
    "输入是两张图片\n",
    "2 x input\n",
    "输出\n",
    "[0.1, 0.2]\n",
    "[0.3, 0.4]\n",
    "预测\n",
    "pred =  [1]\n",
    "        [1]\n",
    "通过argmax将输出变成 pred\n",
    "\n",
    "当合真实的y值比较 Inputs target = [0, 1]\n",
    "通过Preds == inputs target 判断对应位置是否相等\n",
    "[false, true].sum() = 1\n",
    "\n",
    "之所以没有在训练的时候同model.train()\n",
    "在测试的时候用model.eval()\n",
    "是因为这两个只对网络中特定的层起作用如dropout层、batchnorm层\n",
    "但是net并没有\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "684b17d2421240f2bfb163267e97de2a4a7715e49eed0cbb8adb572a33a9a3cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
